package com.ef.dao.logs;

import com.ef.model.exceptions.ExceptionConstants;
import com.ef.model.exceptions.LogEventIDException;
import com.ef.model.exceptions.SqlInsertException;
import com.ef.model.logs.LogRecord;
import com.ef.model.settings.ClientApplicationContext;
import org.apache.log4j.Logger;
import org.springframework.jdbc.core.JdbcTemplate;

import javax.sql.DataSource;
import java.sql.*;
import java.util.List;
import java.util.Map;

public class LogRecordRepository
    extends AbstractRepository {

    private static final Logger LOGGER = Logger.getLogger(LogRecordRepository.class);
    private static final int INSERT_SIZE = 1000;

    /**
     * Set the DataSource that we grab from the Spring Beans in the applicationContext.xml file.
     *
     * @param dataSource
     */
    @Override public void setDataSource(DataSource dataSource) {
        this.jdbcTemplate = new JdbcTemplate(dataSource);
    }

    /**
     * Method used to log the event of this storing of the log file. We need this master table so
     * that we can keep track of which log requests belong to which file.
     *
     * @param logPath - File path of the log file we are parsing.
     * @return - The Auto Generated ID from mysql
     */
    public Integer insertLogEvent(String logPath)
        throws LogEventIDException, SqlInsertException {
        Integer id;

        long startTime = System.currentTimeMillis();

        // Generate a PreparedStatement that way we can have a controlled, secure way of inserting
        // these values to mysql. Put in the try block so that it automatically handles the closing
        // and memory management.
        try (PreparedStatement preparedStatement = this.jdbcTemplate.getDataSource().getConnection()
            .prepareStatement(LogQuery.INSERT_LOG_EVENT.toString(),
                Statement.RETURN_GENERATED_KEYS)) {
            // Set the values for the prepared statement.
            preparedStatement.setString(1, logPath);
            preparedStatement.setTimestamp(2, new Timestamp(System.currentTimeMillis()));
            preparedStatement.executeUpdate();

            // Grab the auto generated ID from mysql so that we can keep track of the records.
            id = grabAutoGeneratedID(preparedStatement);
        } catch (LogEventIDException logException) {
            throw logException;
        } catch (SQLException e) {
            throw new SqlInsertException(
                ExceptionConstants.SQL_INSERT_EXCEPTION_LOG_EVENT.toString());
        }

        long endTime = System.currentTimeMillis();

        LOGGER.info(String.format("Time to insert log event: %d ms", endTime - startTime));

        return id;
    }

    /**
     * Method used to insert all of the records that were parsed from the log file into the database
     * table requestlog. I use multi insert inline queries because it is much more efficient and faster
     * than a bulk insert or any other transaction.
     *
     * @param logRecordList - List of the LogRecord's from the parsed log file.
     * @param id            - The ID of the event log that we are working with.
     */
    public void insertAllRecords(List<LogRecord> logRecordList, Integer id)
        throws SqlInsertException {

        long startTime = System.currentTimeMillis();

        // We need to get the number of times we need to run the bulk insert. Since we are running
        // multi inserts of size 1000 (1000 records per transaction) then we need to divide and get
        // the number of times we must do the insert.
        int numberOfRuns = logRecordList.size() / INSERT_SIZE;
        // We must get the remainder to do the remaining records that do not fall within the 1000
        // multi insert transactions. For example, if there are 1056 records we still need to do a
        // multi insert of 56 records.
        int remainderRun = logRecordList.size() % INSERT_SIZE;
        // Grab the Map of the sql and the number of records that are in the multi insert. We need
        // the number so that we can determine when to execute the batch update from the Prepared
        // Statement.
        Map<String, Integer> sqlMap =
            createMultiInsertQuery(LogQuery.INSERT_LOG_REQUESTS, INSERT_SIZE, remainderRun, 6);

        // Record Count is used to grab the LogRecord from the list. This is independent of the sql
        // query that we are using. Iterates entire list.
        int recordCount = 0;
        for (Map.Entry<String, Integer> sqlEntry : sqlMap.entrySet()) {
            try (PreparedStatement preparedStatement = this.jdbcTemplate.getDataSource()
                .getConnection().prepareStatement(sqlEntry.getKey())) {
                // Count is used to generate the iterators to grab the correct LogRecord to store.
                int count = 0;
                // This count workMore is used to determine if we need to continue iterating through
                // the sql map or not.
                int workMore = 0;
                for (int i = recordCount; recordCount < logRecordList.size(); ++recordCount) {
                    LogRecord logRecord = logRecordList.get(recordCount);
                    preparedStatement.setInt((count * 6) + 1, id);
                    preparedStatement.setString((count * 6) + 2, logRecord.getIpAddress());
                    preparedStatement.setTimestamp((count * 6) + 3,
                        new Timestamp(logRecord.getDate().getTime()));
                    preparedStatement.setString((count * 6) + 4, logRecord.getHttpRequest());
                    preparedStatement.setInt((count * 6) + 5, logRecord.getHttpStatus());
                    preparedStatement.setString((count * 6) + 6, logRecord.getUserAgent());

                    // If count is equal to the insert size value (default as 1000 and then the
                    // remainder) then we need to execute the prepared statement. This is for the
                    // custom multi insert.
                    if (count++ == sqlEntry.getValue() - 1) {
                        preparedStatement.executeLargeUpdate();
                        preparedStatement.clearParameters();
                        count = 0;
                        // If the counter for how many times of the transactions that insert 1000
                        // records is equal to the numberOfRuns value that is determined by the
                        // size of the list of records and the insert size (1000). If true then we
                        // need to break out of this for loop since we are done. Must handle the
                        // remainder inserts afterwards.
                        if (++workMore == numberOfRuns) {
                            // Need to increase the record Count so that for the remainder sql insert
                            // we grab the correct records to insert.
                            ++recordCount;
                            break;
                        }
                    }
                }
            } catch (Exception e) {
                throw new SqlInsertException(
                    ExceptionConstants.SQL_INSERT_EXCEPTION_REQUEST_LOG.toString());
            }
        }

        long endTime = System.currentTimeMillis();

        LOGGER.info(String.format("Time to insert %d log requests: %d ms", logRecordList.size(),
            endTime - startTime));
    }

    /**
     * Method used to insert the IP addresses that were blocked due to the threshold, duration
     * and count of requests that were made. Along with these IP addresses we create a comment based
     * on the duration, threshold and ip address.
     *
     * @param ipAddressList
     * @param clientApplicationContext
     * @param id
     */
    public void insertBlockedRecords(List<String> ipAddressList,
        ClientApplicationContext clientApplicationContext, Integer id)
        throws SqlInsertException {
        long startTime = System.currentTimeMillis();

        // We need to get the number of times we need to run the bulk insert. Since we are running
        // multi inserts of size 1000 (1000 records per transaction) then we need to divide and get
        // the number of times we must do the insert.
        int numberOfRuns = ipAddressList.size() / INSERT_SIZE;
        // We must get the remainder to do the remaining records that do not fall within the 1000
        // multi insert transactions. For example, if there are 1056 records we still need to do a
        // multi insert of 56 records.
        int remainderRun = numberOfRuns == 0 ? 0 : ipAddressList.size() % INSERT_SIZE;
        // Grab the Map of the sql and the number of records that are in the multi insert. We need
        // the number so that we can determine when to execute the batch update from the Prepared
        // Statement.
        Map<String, Integer> sqlMap = createMultiInsertQuery(LogQuery.INSERT_BLOCKED_REQUEST,
            numberOfRuns == 0 ? ipAddressList.size() : INSERT_SIZE, remainderRun, 3);

        // Generate the comment for the IP address using the arguments used to start the application.
        String comment = createCommentForBlocked(clientApplicationContext);

        int recordCount = 0;
        for (Map.Entry<String, Integer> sqlEntry : sqlMap.entrySet()) {
            try (PreparedStatement preparedStatement = this.jdbcTemplate.getDataSource()
                .getConnection().prepareStatement(sqlEntry.getKey())) {
                int count = 0;
                int workMore = 0;
                for (int i = recordCount; recordCount < ipAddressList.size(); ++recordCount) {
                    String ipAddress = ipAddressList.get(recordCount);
                    preparedStatement.setInt((count * 3) + 1, id);
                    preparedStatement.setString((count * 3) + 2, ipAddress);
                    preparedStatement.setString((count * 3) + 3, String.format(comment, ipAddress));

                    if (count++ == sqlEntry.getValue() - 1) {
                        preparedStatement.executeLargeUpdate();
                        preparedStatement.clearParameters();
                        count = 0;
                        if (++workMore == numberOfRuns) {
                            ++recordCount;
                            break;
                        }
                    }
                }
            } catch (Exception e) {
                throw new SqlInsertException(
                    ExceptionConstants.SQL_INSERT_EXCEPTION_BLOCKED_REQUEST.toString());
            }
        }

        long endTime = System.currentTimeMillis();

        LOGGER.info(String.format("Time to insert %d blocked requests: %d ms", ipAddressList.size(),
            endTime - startTime));
    }

    /**
     * Method used to generate the comment for the IP addresses that were blocked due to the
     * threshold and duration.
     *
     * @param clientApplicationContext - Contains the arguments provided by the user on startup.
     * @return
     */
    private String createCommentForBlocked(ClientApplicationContext clientApplicationContext) {
        StringBuilder builder = new StringBuilder();

        builder.append("IP Address %s ");
        builder.append(String
            .format("has been blocked for making more than %d requests between %s and %s.",
                clientApplicationContext.getThreshold(),
                clientApplicationContext.getStartDate().toString(),
                clientApplicationContext.getEndDate().toString()));

        return builder.toString();
    }

}
